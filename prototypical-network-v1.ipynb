{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-01T04:54:15.393043Z","iopub.execute_input":"2023-05-01T04:54:15.393571Z","iopub.status.idle":"2023-05-01T04:54:15.420506Z","shell.execute_reply.started":"2023-05-01T04:54:15.393522Z","shell.execute_reply":"2023-05-01T04:54:15.419285Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/lsa64-matrix-10-classes-v1/padded_matrix_file.csv\n/kaggle/input/te-v2-model/model_epoch_92.pt\n/kaggle/input/lsa64-matrix-unseen-5/LSA64-matrix-unseen-5.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport csv\nimport ast\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.manifold import TSNE\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import LabelEncoder\nimport random\nfrom torch.optim import Adam\nfrom torch.nn.functional import cross_entropy\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:15.423569Z","iopub.execute_input":"2023-05-01T04:54:15.424380Z","iopub.status.idle":"2023-05-01T04:54:15.433493Z","shell.execute_reply.started":"2023-05-01T04:54:15.424320Z","shell.execute_reply":"2023-05-01T04:54:15.432503Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Your code for loading the data (unchanged)\ninput_file = \"/kaggle/input/lsa64-matrix-unseen-5/LSA64-matrix-unseen-5.csv\"\n\nvalues = []\nmatrix_labels = []\nnum_rows = 0\n\nwith open(input_file, \"r\") as f_input:\n    reader = csv.reader(f_input)\n    for row in reader:\n        row_values = []\n        for i in range(len(row) - 1):\n            column_value = ast.literal_eval(row[i])\n            row_values.append(column_value)\n        values.append(torch.tensor(row_values))\n        matrix_labels.append(ast.literal_eval(row[-1]))\n        num_rows += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:15.435034Z","iopub.execute_input":"2023-05-01T04:54:15.435619Z","iopub.status.idle":"2023-05-01T04:54:30.662271Z","shell.execute_reply.started":"2023-05-01T04:54:15.435579Z","shell.execute_reply":"2023-05-01T04:54:30.661189Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, n_features, d_model=64, nhead=64, num_layers=1):\n        super(TransformerEncoder, self).__init__()\n        self.embedding = nn.Linear(n_features, d_model)\n        self.positional_encoding = self.generate_positional_encoding(d_model)\n        self.transformer_encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model, nhead), num_layers\n        )\n\n    def generate_positional_encoding(self, d_model, max_len=243):\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        return pe.unsqueeze(0)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x + self.positional_encoding[:, : x.size(1)]\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:30.663862Z","iopub.execute_input":"2023-05-01T04:54:30.665256Z","iopub.status.idle":"2023-05-01T04:54:30.676911Z","shell.execute_reply.started":"2023-05-01T04:54:30.665191Z","shell.execute_reply":"2023-05-01T04:54:30.675973Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained transformer encoder\nencoder = TransformerEncoder(114)\nencoder.load_state_dict(torch.load(\"/kaggle/input/te-v2-model/model_epoch_92.pt\"))\nencoder.eval()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:30.679875Z","iopub.execute_input":"2023-05-01T04:54:30.681371Z","iopub.status.idle":"2023-05-01T04:54:30.750854Z","shell.execute_reply.started":"2023-05-01T04:54:30.681316Z","shell.execute_reply":"2023-05-01T04:54:30.749537Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TransformerEncoder(\n  (embedding): Linear(in_features=114, out_features=64, bias=True)\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n        )\n        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Extract features\nembeddings = encoder(torch.stack(values))\nlabels = np.array(matrix_labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:30.753175Z","iopub.execute_input":"2023-05-01T04:54:30.754204Z","iopub.status.idle":"2023-05-01T04:54:37.663157Z","shell.execute_reply.started":"2023-05-01T04:54:30.754146Z","shell.execute_reply":"2023-05-01T04:54:37.661825Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def create_few_shot_task(embeddings, labels, n_way, k_shot, n_query):\n    unique_labels = np.unique(labels)\n    selected_labels = np.random.choice(unique_labels, n_way, replace=False)\n    \n    support_set = []\n    query_set = []\n    support_labels = []\n    query_labels = []\n    \n    for label in selected_labels:\n        class_embeddings = embeddings[labels == label]\n        support_indices = np.random.choice(range(len(class_embeddings)), k_shot, replace=False)\n        query_indices = np.random.choice(np.delete(range(len(class_embeddings)), support_indices), n_query, replace=False)\n        \n        support_set.append(class_embeddings[support_indices].detach().numpy())\n        query_set.append(class_embeddings[query_indices].detach().numpy())\n        support_labels.extend([label] * k_shot)\n        query_labels.extend([label] * n_query)\n    \n    support_set = np.concatenate(support_set, axis=0)\n    query_set = np.concatenate(query_set, axis=0)\n    support_labels = np.array(support_labels)\n    query_labels = np.array(query_labels)\n    \n    return support_set, query_set, support_labels, query_labels\n","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:37.664901Z","iopub.execute_input":"2023-05-01T04:54:37.665315Z","iopub.status.idle":"2023-05-01T04:54:37.676892Z","shell.execute_reply.started":"2023-05-01T04:54:37.665275Z","shell.execute_reply":"2023-05-01T04:54:37.675398Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# n-way k-shot parameters\nn_way = 10\nk_shot = 2\nn_query = 2\nn_episodes = 100\n\n# Episodic evaluation\naccuracies = []\n\nfor episode in range(n_episodes):\n    support_set, query_set, support_labels, query_labels = create_few_shot_task(embeddings, labels, n_way, k_shot, n_query)\n\n    # Compute the class prototypes using the support set\n    support_class_prototypes = np.zeros((n_way, embeddings.shape[-1]))\n    for idx, label in enumerate(np.unique(support_labels)):\n        support_class_prototypes[idx] = support_set[support_labels == label].mean(axis=0)\n\n    # Compute distances between the query instances and the class prototypes\n    distances = np.linalg.norm(support_class_prototypes[:, None] - query_set, axis=-1)\n\n    # Classification\n    predicted_labels = np.argmin(distances, axis=0)\n    predicted_labels = np.array([np.unique(support_labels)[label_idx] for label_idx in predicted_labels])\n\n    # Evaluate the performance\n    accuracy = accuracy_score(query_labels, predicted_labels)\n    accuracies.append(accuracy)\n\nmean_accuracy = np.mean(accuracies)\nprint(f\"{n_way}-way {k_shot}-shot mean accuracy over {n_episodes} episodes: {mean_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:37.678577Z","iopub.execute_input":"2023-05-01T04:54:37.679553Z","iopub.status.idle":"2023-05-01T04:54:38.067140Z","shell.execute_reply.started":"2023-05-01T04:54:37.679508Z","shell.execute_reply":"2023-05-01T04:54:38.065173Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/331658994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msupport_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_few_shot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Compute the class prototypes using the support set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3397983182.py\u001b[0m in \u001b[0;36mcreate_few_shot_task\u001b[0;34m(embeddings, labels, n_way, k_shot, n_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_few_shot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0munique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mselected_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msupport_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"],"ename":"ValueError","evalue":"Cannot take a larger sample than population when 'replace=False'","output_type":"error"}]},{"cell_type":"code","source":"# Create a new few-shot task for demonstration purposes\nsupport_set, query_set, support_labels, query_labels = create_few_shot_task(embeddings, labels, n_way, k_shot, n_query)\n\n# Compute the class prototypes using the support set\nsupport_class_prototypes = np.zeros((n_way, embeddings.shape[-1]))\nfor idx, label in enumerate(np.unique(support_labels)):\n    support_class_prototypes[idx] = support_set[support_labels == label].mean(axis=0)\n\n# Run t-SNE for 2D visualization\ntsne = TSNE(n_components=2, random_state=42)\nall_embeddings = np.vstack((support_set, query_set, support_class_prototypes))\nall_embeddings_2d = tsne.fit_transform(all_embeddings)\n\n# Prepare the data for visualization\nsupport_labels_str = [str(x) for x in support_labels.tolist()]\nquery_labels_str = [str(x) for x in query_labels.tolist()]\nprototype_labels_str = [str(x) for x in set(support_labels.tolist())]\n\nsupport_types = ['support'] * len(support_labels)\nquery_types = ['query'] * len(query_labels)\nprototype_types = ['prototype'] * len(prototype_labels_str)\n\nall_labels = support_labels_str + query_labels_str + prototype_labels_str\nall_types = support_types + query_types + prototype_types\n\ndf = pd.DataFrame({'x': all_embeddings_2d[:, 0], 'y': all_embeddings_2d[:, 1], 'label': all_labels, 'type': all_types})\n\n# Create the plot\nfig = go.Figure()\n\n# Add support set points\nsupport_df = df[df['type'] == 'support']\nfig.add_trace(go.Scatter(x=support_df['x'], y=support_df['y'], mode='markers', marker=dict(symbol='circle', size=8),\n                         text=support_df['label'], customdata=support_df['type'], name='Support Set',\n                         hovertemplate='Label: %{text}<br>Type: %{customdata}<extra></extra>'))\n\n# Add query set points\nquery_df = df[df['type'] == 'query']\nfig.add_trace(go.Scatter(x=query_df['x'], y=query_df['y'], mode='markers', marker=dict(symbol='star', size=10),\n                         text=query_df['label'], customdata=query_df['type'], name='Query Set',\n                         hovertemplate='Label: %{text}<br>Type: %{customdata}<extra></extra>'))\n\n# Add prototype points\nprototype_df = df[df['type'] == 'prototype']\nfig.add_trace(go.Scatter(x=prototype_df['x'], y=prototype_df['y'], mode='markers', marker=dict(symbol='x', size=12),\n                         text=prototype_df['label'], customdata=prototype_df['type'], name='Prototypes',\n                         hovertemplate='Label: %{text}<br>Type: %{customdata}<extra></extra>'))\n\nfig.update_layout(title='2D t-SNE Visualization of Embeddings',\n                  xaxis_title='t-SNE Component 1',\n                  yaxis_title='t-SNE Component 2')\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:54:38.068928Z","iopub.status.idle":"2023-05-01T04:54:38.069865Z","shell.execute_reply.started":"2023-05-01T04:54:38.069528Z","shell.execute_reply":"2023-05-01T04:54:38.069559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}